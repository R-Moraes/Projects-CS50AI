We started the tests with the same neural network structure as the example shown in class, we just changed the amount of neurons to 50 and with that, we got an accuracy of 0.95 and a loss of 0.45. Then we changed the activation function to ELU, which brought us an accuracy of 0.97 and a loss of 0.1098.
So we decided to change the pool_size to (3.3) and with that, we got the following results:
Accuracy = 0.94
loss = 0.3572. Finally, we changed the activation function to sigmoid and added another hidden layer which brought us the following results:
Accuracy: 0.9675
loss: 0.1138